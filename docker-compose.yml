---
# ----------------------------------------------------------------------------------------
# A docker compose stack with Spark, Jupyterlab, Scala, postgres
# ----------------------------------------------------------------------------------------
version: "3.8"
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
  db:
    name: "db"
    driver: local
  minio_data:
    name: "minio_data"
    driver: local
services:
# Jupyer lab
  jupyterlab:
    image: jupyterlab-custom:latest
    restart: always
    container_name: jupyterlab
    ports:
      - 8888:8888
      - 4040:4040
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_DEFAULT_REGION=us-east-1
    volumes:
      - ./workspace:/opt/workspace
# Spark      
  spark-master:
    image: spark-master:3.0.0
    restart: always
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - ./workspace:/opt/workspace
  spark-worker-1:
    image: spark-worker:3.0.0
    restart: always
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512M
    ports:
      - 8081:8081
    volumes:
      - ./workspace:/opt/workspace
    depends_on:
      - spark-master
  spark-worker-2:
    image: spark-worker:3.0.0
    restart: always
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512M
    ports:
      - 8082:8081
    volumes:
      - ./workspace:/opt/workspace
    depends_on:
      - spark-master